Natural Language Processing with Python
=======================================

Chapter 1
=========
Language Processing and Python

nltk.download() to download all corpus for the book.

corpus: nltk.book

Searching text:
concordance() - works like grep
Usage: text1.concordance(word)
Make sure to create a nltk.text object of a corpus to use concordance function on it.

similar() - Showing words having similar context in the corpus
Usage: text1.similar(word)

common_context() - Showing context shared by two or more words
Usage: text1.common_context([word1, word2, ...])

dispersion_plot() - Showing positional information of word in a corpus
Usage: text1.dispersion_plot([word1, word2, ...])

generate() - Generate random text from the corpus
Usage: text1.generate() - Not found in nltk 3.0

len() - find the lenght of a string
Usage: len(string)

set() - find distinct words
Usage: set(string)

Lexical richness of the text:
len(string) / len(set(string))

count() - count the occurance of a word
Usage: string.count(word)

FreqDist() - Output the frequency distribution in dict format
Usage: FreqDist(string)

Cumulative frequency plot:
Usage: dict.plot(count, cumulative=True)

collocations() - Bigrams that occur more often
Usage: text4.collocations()

Challenges in NLP:
a. Word Sense Disambiguation:
For e.g He serve the dish.

b. Pronoun Resolution:
For e.g The thieves stole the paintings. They were sold.

c. Generating Language Output:
Usage: Question answering and Machine Translation

d. Machine Translation:
babelize_shell() - To make the translation back and forth between two languages
Note: No longer works

e. Spoken Dialogue Systems:
Siri or Google Now

f. Textual Entailment:
Directional relation between text fragments
For e.g
Text: David Golinkin is the editor or author of 18 books, and over 150 responsa, articles, sermons and books
Hypothesis: Golinkin has written 18 books

===============================================================================================================
